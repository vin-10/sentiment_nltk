{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport nltk \nimport seaborn as sns\n\nplt.style.use(\"ggplot\")# stylesheet (it is the colors or the way of repsresntation of graphs in different ways)used for graph plotting \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"0dbfefd1-595b-4817-8c09-a258d4c115aa","_cell_guid":"5d205f98-a7f0-4517-bf2d-103ca47e5f0a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:01:56.715057Z","iopub.execute_input":"2022-06-27T19:01:56.715518Z","iopub.status.idle":"2022-06-27T19:01:56.728866Z","shell.execute_reply.started":"2022-06-27T19:01:56.715488Z","shell.execute_reply":"2022-06-27T19:01:56.727318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"HERE two techniques are using (i.)VADER and (ii.)ROBERTA model (by hugging face ) and finally use a hugging face pipelines","metadata":{"_uuid":"feae9b90-f847-48e6-ba4a-882ed992e961","_cell_guid":"b73cd966-525b-46a7-9072-425e16773f06","trusted":true}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/amazon-fine-food-reviews/Reviews.csv\")\ndf.head()\ndf.shape# gives the total data with rows and columns\n#df.[\"Text\"].value[0] # gives me the text column first entry \n# here the summary contains the data to be reviewed or used  and score is the stars given \n\n# scaling down the data by selecting only 500 entries\ndf=df.head(500)\ndf.shape","metadata":{"_uuid":"9e4b81c3-3bbe-4221-a5ba-8d010433c432","_cell_guid":"ba9b295e-3e65-46a1-b773-921cbbb7b751","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:01:56.732207Z","iopub.execute_input":"2022-06-27T19:01:56.732583Z","iopub.status.idle":"2022-06-27T19:02:00.983546Z","shell.execute_reply.started":"2022-06-27T19:01:56.732553Z","shell.execute_reply":"2022-06-27T19:02:00.982157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax=df[\"Score\"].value_counts().sort_index().plot(kind=\"bar\",title=\"Count of Reviews\",figsize=(10,5))\nax.set_xlabel(\"RATINGS STARS\")","metadata":{"_uuid":"26bf7a53-d853-48e7-b9cc-e9f1ad93894c","_cell_guid":"e589e0c0-a1db-42a8-9d2c-2a684275c135","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:00.988398Z","iopub.execute_input":"2022-06-27T19:02:00.988822Z","iopub.status.idle":"2022-06-27T19:02:01.188589Z","shell.execute_reply.started":"2022-06-27T19:02:00.98879Z","shell.execute_reply":"2022-06-27T19:02:01.187089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1. VADER Seniment Scoring\nWe will use NLTK's SentimentIntensityAnalyzer to get the neg/neu/pos scores of the text. (it doesn't account for the relationship betweenn the data )\n\nThis uses a \"bag of words\" approach:\n1.Stop words are removed \n2.each word is scored and combined to a total score.","metadata":{"_uuid":"fa4d960e-4d9a-445b-ab4d-397fe140ed16","_cell_guid":"82250610-12b8-4faa-bcf1-82d251861597","trusted":true}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nfrom tqdm.notebook import tqdm   # used to show the progress report or bars \n\nsia=SentimentIntensityAnalyzer()","metadata":{"_uuid":"fca01f6c-7769-4cb2-bc3d-cab84733cefe","_cell_guid":"c48abfca-d202-405f-8f35-1d364d7acef7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.190587Z","iopub.execute_input":"2022-06-27T19:02:01.190952Z","iopub.status.idle":"2022-06-27T19:02:01.206043Z","shell.execute_reply.started":"2022-06-27T19:02:01.19092Z","shell.execute_reply":"2022-06-27T19:02:01.205171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sia.polarity_scores(\"I am sad\")\nsia.polarity_scores(\"I am happy\") \n#  compound is the average of all and gives an overall view of the sentences /words","metadata":{"_uuid":"50f5b919-8066-45e5-8983-f0bb3fe14010","_cell_guid":"66c09871-0dc7-400a-bafd-a2671eb2d601","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.208415Z","iopub.execute_input":"2022-06-27T19:02:01.208961Z","iopub.status.idle":"2022-06-27T19:02:01.220371Z","shell.execute_reply.started":"2022-06-27T19:02:01.208929Z","shell.execute_reply":"2022-06-27T19:02:01.219564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  running on the data set \nres={}\nfor i, row in tqdm(df.iterrows(),total=len(df)):\n    text=row[\"Text\"]# text contains the comments to be analysed \n    myid=row[\"Id\"]\n    res[myid]=sia.polarity_scores(text)","metadata":{"_uuid":"2f807578-53b0-4f4f-94eb-fd2bedee4a82","_cell_guid":"1755fc29-2a1f-4320-9c09-b545be5dbc35","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.221789Z","iopub.execute_input":"2022-06-27T19:02:01.22232Z","iopub.status.idle":"2022-06-27T19:02:01.890431Z","shell.execute_reply.started":"2022-06-27T19:02:01.22229Z","shell.execute_reply":"2022-06-27T19:02:01.888584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting into pandas dataframe\n# pd.DataFrame(res)# pandas acan easily intake the dictonaries\nvaders=pd.DataFrame(res).T # TO GET IN VERTICAL TABLES FORM .T IS used\nvaders.head()","metadata":{"_uuid":"2a61646a-0e25-4479-9c45-174f023edc08","_cell_guid":"ba9a8a86-d36e-4d86-a715-cd0baa4be575","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.892434Z","iopub.execute_input":"2022-06-27T19:02:01.892889Z","iopub.status.idle":"2022-06-27T19:02:01.93567Z","shell.execute_reply.started":"2022-06-27T19:02:01.892825Z","shell.execute_reply":"2022-06-27T19:02:01.93437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  changing the index to id and the merging into original datset \nvaders=vaders.reset_index().rename(columns={\"index\":\"Id\"})\nvaders=vaders.merge(df,how=\"left\")\nvaders","metadata":{"_uuid":"f8d8331c-352d-4398-8b02-3e1afb68f0c5","_cell_guid":"f8444c85-3c4a-44d9-b0b0-e202cf569362","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.936842Z","iopub.execute_input":"2022-06-27T19:02:01.937337Z","iopub.status.idle":"2022-06-27T19:02:01.976207Z","shell.execute_reply.started":"2022-06-27T19:02:01.937304Z","shell.execute_reply":"2022-06-27T19:02:01.974945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  plotting the results \nax = sns.barplot(data=vaders,x=\"Score\",y=\"compound\")\nfig,axs=plt.subplots(1,3,figsize=(12,3))\nsns.barplot(data=vaders,x=\"Score\",y=\"pos\",ax=axs[0])\nsns.barplot(data=vaders,x=\"Score\",y=\"neu\",ax=axs[1])\nsns.barplot(data=vaders,x=\"Score\",y=\"pos\",ax=axs[2])\naxs[0].set_title(\"positive\")\naxs[1].set_title(\"Neutral\")\naxs[2].set_title(\"Negative\")","metadata":{"_uuid":"a34293b7-fb8a-4fee-adbd-4efbc795a978","_cell_guid":"e1d8340b-386a-40e5-a300-23795d5a706c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:01.979108Z","iopub.execute_input":"2022-06-27T19:02:01.979473Z","iopub.status.idle":"2022-06-27T19:02:03.17776Z","shell.execute_reply.started":"2022-06-27T19:02:01.979445Z","shell.execute_reply":"2022-06-27T19:02:03.176336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# roberta pretrained model","metadata":{"_uuid":"be52a975-d0e0-4017-aba6-a0c38c44da42","_cell_guid":"60da41cf-6513-408b-ad2f-17e9e2768b41","trusted":true}},{"cell_type":"code","source":"from transformers import AutoTokenizer # taking from hugging faces\nfrom transformers import AutoModelForSequenceClassification\nfrom scipy.special import softmax","metadata":{"_uuid":"d726baad-619f-4ed8-93f2-4ab07255271b","_cell_guid":"2278c366-e4d9-4c9e-896c-b15ec9efced8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:03.17925Z","iopub.execute_input":"2022-06-27T19:02:03.179547Z","iopub.status.idle":"2022-06-27T19:02:03.185584Z","shell.execute_reply.started":"2022-06-27T19:02:03.17952Z","shell.execute_reply":"2022-06-27T19:02:03.184592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  doing transfer learning we are taking trained weights and using that in our mmodel\nMODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)","metadata":{"_uuid":"c2c7d5d3-10c6-4116-be87-648fb2eeb0f5","_cell_guid":"86620491-2225-4a07-9aac-6a4610eb30e1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:02:03.188895Z","iopub.execute_input":"2022-06-27T19:02:03.189492Z","iopub.status.idle":"2022-06-27T19:02:16.909364Z","shell.execute_reply.started":"2022-06-27T19:02:03.18946Z","shell.execute_reply":"2022-06-27T19:02:16.908339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polarity_scores_roberta(example):\n    encoded_text = tokenizer(example, return_tensors='pt') # encoding the text into ,\n    output = model(**encoded_text) # gives into tensor\n    scores = output[0][0].detach().numpy() # convrtedd into numpy \n    scores = softmax(scores) #Softmax is a mathematical function that converts a vector of numbers into a vector of probabilities, where the probabilities of each value are proportional to the relative scale of each value in the vector\n    scores_dict = {\n        'roberta_neg' : scores[0],\n        'roberta_neu' : scores[1],\n        'roberta_pos' : scores[2]\n    }\n    return scores_dict","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:02:16.911222Z","iopub.execute_input":"2022-06-27T19:02:16.911949Z","iopub.status.idle":"2022-06-27T19:02:16.919751Z","shell.execute_reply.started":"2022-06-27T19:02:16.911901Z","shell.execute_reply":"2022-06-27T19:02:16.918959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = {}\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    try:\n        text = row['Text']\n        myid = row['Id']\n        vader_result = sia.polarity_scores(text)\n        vader_result_rename = {}\n        for key, value in vader_result.items():\n            vader_result_rename[f\"vader_{key}\"] = value\n        roberta_result = polarity_scores_roberta(text)\n        both = {**vader_result_rename, **roberta_result}\n        res[myid] = both\n    except RuntimeError:\n        print(f'Broke for id {myid}')","metadata":{"_uuid":"962a9f3e-a4a4-4197-a19f-0fa2b4b92c9b","_cell_guid":"4fd52734-4e37-4d6b-834b-5dc7cc47b9cb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-27T19:04:04.164527Z","iopub.execute_input":"2022-06-27T19:04:04.165029Z","iopub.status.idle":"2022-06-27T19:05:51.124106Z","shell.execute_reply.started":"2022-06-27T19:04:04.164993Z","shell.execute_reply":"2022-06-27T19:05:51.122621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df=pd.DataFrame(res).T\nresults_df=results_df.reset_index().rename(columns={\"index\":\"Id\"})\nresults_df= results_df.merge(df,how=\"left\")\nresults_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:14:45.435022Z","iopub.execute_input":"2022-06-27T19:14:45.436287Z","iopub.status.idle":"2022-06-27T19:14:45.476436Z","shell.execute_reply.started":"2022-06-27T19:14:45.436243Z","shell.execute_reply":"2022-06-27T19:14:45.4752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot used for comparison \nsns.pairplot(data=results_df,vars=['vader_neg', 'vader_neu', 'vader_pos','roberta_neg', 'roberta_neu', 'roberta_pos'],hue=\"Score\",palette=\"tab10\")\nplt.show()                                   ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:18:03.596349Z","iopub.execute_input":"2022-06-27T19:18:03.596833Z","iopub.status.idle":"2022-06-27T19:18:15.714512Z","shell.execute_reply.started":"2022-06-27T19:18:03.596799Z","shell.execute_reply":"2022-06-27T19:18:15.713195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  comments are positive but still the user gave 1 star\nresults_df.query(\"Score==1\")\\\n .sort_values(\"roberta_pos\",ascending=False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:23:35.671334Z","iopub.execute_input":"2022-06-27T19:23:35.671831Z","iopub.status.idle":"2022-06-27T19:23:35.690339Z","shell.execute_reply.started":"2022-06-27T19:23:35.671787Z","shell.execute_reply":"2022-06-27T19:23:35.688982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  negative sentiment but 5  star\nresults_df.query(\"Score==5\")\\\n.sort_values(\"roberta_neg\",ascending=False)[\"Text\"].values[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:26:42.994811Z","iopub.execute_input":"2022-06-27T19:26:42.995364Z","iopub.status.idle":"2022-06-27T19:26:43.008904Z","shell.execute_reply.started":"2022-06-27T19:26:42.995332Z","shell.execute_reply":"2022-06-27T19:26:43.007928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using hugging face pipelines","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nsentiment_pipeline =pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:30:38.925306Z","iopub.execute_input":"2022-06-27T19:30:38.925944Z","iopub.status.idle":"2022-06-27T19:30:51.858203Z","shell.execute_reply.started":"2022-06-27T19:30:38.925896Z","shell.execute_reply":"2022-06-27T19:30:51.856828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sentiment_pipeline(\"I love u\")\n# sentiment_pipeline(\"I hate u\")\nsentiment_pipeline(\"oops\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T19:32:19.665245Z","iopub.execute_input":"2022-06-27T19:32:19.666593Z","iopub.status.idle":"2022-06-27T19:32:19.713743Z","shell.execute_reply.started":"2022-06-27T19:32:19.666537Z","shell.execute_reply":"2022-06-27T19:32:19.712644Z"},"trusted":true},"execution_count":null,"outputs":[]}]}